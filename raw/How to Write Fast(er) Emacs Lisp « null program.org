#+TITLE: How to Write Fast(er) Emacs Lisp « null program
#+URL: http://nullprogram.com/blog/2017/01/30/
#+AUTHOR: lujun9972
#+TAGS: raw
#+DATE: [2017-02-10 五 21:59]
#+LANGUAGE:  zh-CN
#+OPTIONS:  H:6 num:nil toc:t \n:nil ::t |:t ^:nil -:nil f:t *:t <:nil

不是所有的EmacsLisp代码都需要优化速度. Emacs本身就有大约82%是由EmacsLisp来实现的,这些用EmacsLisp实现的功能一般都对性能不敏感. 那些对性能有要求的函数都用C来实现了.
对Emacs的扩展,即时对性能有要求,也只能用EmacsLisp来实现,别无他法(当然 [[http://nullprogram.com/blog/2016/11/05/][dynamic modules]] 和 调用外部程序这两种方法除外).
一般自动缩进, [[https://github.com/mooz/js2-mode][语法树分析]], 以及 [[http://nullprogram.com/blog/2016/12/11/][自动补全]] 这几大类插件对性能要求都较高.

有5条针对EmacsLisp的准则可以改善代码性能. 这些准则并不会为了性能而牺牲掉代码的可读性.

需要说明的是: 这些准则只是针对 Emacs 25.1 及相近的版本来说的. Emacs不断的在改进. 对[[http://nullprogram.com/blog/2014/01/04/][虚拟机]] 和 字节码编译器的修改可能会将当前运行很慢的表达式优化成快速的字节码,从而使得这些准则变得过时.
未来如果真的有这种情况发生的话,我会再对本文做出修改.

* (1) Use lexical scope

本准则要求你在写EmacsLisp时始终将下面这行内容作为文件的首行.

#+BEGIN_SRC emacs-lisp
  ;;; -*- lexical-binding: t; -*-
#+END_SRC

无论怎么强调这点都不过分. 这不仅仅使得[[http://nullprogram.com/blog/2016/12/22/][你的代码更健壮]] 还能显著地提高代码的运行速度.
而且对于那些特殊变量(译者注:defvar,defconst,defcustom定义的变量)来说,它们依然是处于动态作用域下的,所以完全没有什么理由不用静态作用域.
你在动态作用域下编写的代码即时切换到动态作用域下也不会影响到它的功能.

特殊变量要比局部变量和静态作用域下的变量慢得多,因此请只在必要的时候才用.

* (2) Prefer built-in functions

内建函数使用C写的,当然会比用EmacsLisp写得同类函数要快得多. 请尽量用内建函数来完成工作,即使因此会增加代码语句.

举个例子, 创建一个累加队列的最快方法是什么? 也就是说新元素要不断累加到列表的末尾,而且应算法的要求,列表必须从头部开始组建.

你可能会尝试追踪列表的末尾位置,然后使用 =setcdr(由下面的setf来调用)= 来将新元素直接添加到列表的末尾处.

#+BEGIN_SRC emacs-lisp
  (defun fib-track-tail (n)
    (let* ((a 0)
           (b 1)
           (head (list 1))
           (tail head))
      (dotimes (_ n head)
        (psetf a b
               b (+ a b))
        (setf (cdr tail) (list b)
              tail (cdr tail)))))

  (fib-track-tail 8)
  ;; => (1 1 2 3 5 8 13 21 34)
#+END_SRC

然而实际上,先创建一个逆序的列表,然后反转它要快得多.

#+BEGIN_SRC emacs-lisp
  (defun fib-nreverse (n)
    (let* ((a 0)
           (b 1)
           (list (list 1)))
      (dotimes (_ n (nreverse list))
        (psetf a b
               b (+ a b))
        (push b list))))
#+END_SRC

你可能不相信,但是 =nreverse= 非常的快. 不仅仅因为它是内建函数,它甚至有自己的操作码!
在循环中使用push然后在最用用nreverse反转列表是创建累加列表的最快方法.

在 fib-track-tail 中, 用EmacsLisp追中列表尾部,不仅增加了复杂度而且要比用C遍历两次列表要慢得多.

* (3) Avoid unnecessary lambda functions

I’m talking about mapcar and friends.

#+BEGIN_SRC emacs-lisp
  ;; Slower
  (defun expt-list (list e)
    (mapcar (lambda (x) (expt x e)) list))
#+END_SRC

Listen, I know you love [[https://github.com/magnars/dash.el][dash.el]] and higher order functions, but this habit
ain’t cheap. The byte-code compiler does not know how to inline these lambdas,
so there’s an additional per-element function call overhead.

Worse, if you’re using lexical scope like I told you, the above example forms
a closure over e. This means a new function object is created (e.g.
make-byte-code) each time expt-list is called. To be clear, I don’t mean that
the lambda is recompiled each time — the same byte-code string is shared
between all instances of the same lambda. A unique function vector (#[...])
and constants vector are allocated and initialized each time expt-list is
invoked.

Related mini-guideline: Don’t create any more garbage than strictly necessary
in performance-critical code.

Compare to an implementation with an explicit loop, using the nreverse
list-accumulation technique.

#+BEGIN_SRC emacs-lisp
  (defun expt-list-fast (list e)
    (let ((result ()))
      (dolist (x list (nreverse result))
        (push (expt x e) result))))
#+END_SRC

+ No unnecessary garbage is created.
+ No unnecessary per-element function calls.

This is the fastest possible definition for this function, and it’s what you
need to use in performance-critical code.

Personally I prefer the list comprehension approach, using cl-loop from
cl-lib.

#+BEGIN_SRC emacs-lisp
  (defun expt-list-fast (list e)
    (cl-loop for x in list
             collect (expt x e)))
#+END_SRC

The cl-loop macro will expand into essentially the previous definition, making
them practically equivalent. It takes some getting used to, but writing
efficient loops is a whole lot less tedious with cl-loop.

In Emacs 24.4 and earlier, catch/throw is implemented by converting the body
of the catch into a lambda function and calling it. If code inside the catch
accesses a variable outside the catch (very likely), then, in lexical scope,
it turns into a closure, resulting in the garbage function object like before.

In Emacs 24.5 and later, the byte-code compiler uses a new opcode, pushcatch.
It’s a whole lot more efficient, and there’s no longer a reason to shy away
from catch/throw in performance-critical code. This is important because it’s
often the only way to perform an early bailout.

* (4) Prefer using functions with dedicated opcodes

When following the guideline about using built-in functions, you might have
several to pick from. Some built-in functions have dedicated virtual machine
opcodes, making them much faster to invoke. Prefer these functions when
possible.

How can you tell when a function has an assigned opcode? Take a peek at the
byte-defop listings in [[https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/bytecomp.el][bytecomp.el]]. Optimization often involves getting into
the weeds, so don’t be shy.

For example, the assq and assoc functions search for a matching key in an
association list (alist). Both are built-in functions, and the only difference
is that the former compares keys with eq (e.g. symbol or integer keys) and the
latter with equal (typically string keys). The difference in performance
between eq and equal isn’t as important as another factor: assq has its own
opcode (158).

This means in performance-critical code you should prefer assq, perhaps even
going as far as restructuring your alists specifically to have eq keys. That
last step is probably a trade-off, which means you’ll want to make some
benchmarks to help with that decision.

Another example is eq, =, eql, and equal. Some macros and functions use eql,
especially cl-lib which inherits eql as a default from Common Lisp. Take
cl-case, which is like switch from the C family of languages. It compares
elements with eql.

#+BEGIN_SRC emacs-lisp
  (defun op-apply (op a b)
    (cl-case op
      (:norm (+ (* a a) (* b b)))
      (:disp (abs (- a b)))
      (:isin (/ b (sin a)))))
#+END_SRC

The cl-case expands into a cond. Since Emacs byte-code lacks support for jump
tables, there’s not much room for cleverness.

#+BEGIN_SRC emacs-lisp
  (defun op-apply (op a b)
    (cond
     ((eql op :norm) (+ (* a a) (* b b)))
     ((eql op :disp) (abs (- a b)))
     ((eql op :isin) (/ b (sin a)))))
#+END_SRC

It turns out eql is pretty much always the worst choice for cl-case. Of the
four equality functions I listed, the only one lacking an opcode is eql. A
faster definition would use eq. (In theory, cl-case could have done this
itself because it knows all the keys are symbols.)

#+BEGIN_SRC emacs-lisp
  (defun op-apply (op a b)
    (cond
     ((eq op :norm) (+ (* a a) (* b b)))
     ((eq op :disp) (abs (- a b)))
     ((eq op :isin) (/ b (sin a)))))
#+END_SRC

Fortunately eq can safely compare integers in Emacs Lisp. You only need eql
when comparing symbols, integers, and floats all at once, which is unusual.

* (5) Unroll loops using and/or

Consider the following function which checks its argument against a list of
numbers, bailing out on the first match. I used % instead of mod since the
former has an opcode (166) and the latter does not.

#+BEGIN_SRC emacs-lisp
  (defun detect (x)
    (catch 'found
      (dolist (f '(2 3 5 7 11 13 17 19 23 29 31))
        (when (= 0 (% x f))
          (throw 'found f)))))
#+END_SRC

The byte-code compiler doesn’t know how to unroll loops. Fortunately that’s
something we can do for ourselves using and and or. The compiler will turn
this into clean, efficient jumps in the byte-code.

#+BEGIN_SRC emacs-lisp
  (defun detect-unrolled (x)
    (or (and (= 0 (% x 2)) 2)
        (and (= 0 (% x 3)) 3)
        (and (= 0 (% x 5)) 5)
        (and (= 0 (% x 7)) 7)
        (and (= 0 (% x 11)) 11)
        (and (= 0 (% x 13)) 13)
        (and (= 0 (% x 17)) 17)
        (and (= 0 (% x 19)) 19)
        (and (= 0 (% x 23)) 23)
        (and (= 0 (% x 29)) 29)
        (and (= 0 (% x 31)) 31)))
#+END_SRC

In Emacs 24.4 and earlier with the old-fashioned lambda-based catch, the
unrolled definition is seven times faster. With the faster pushcatch-based
catch it’s about twice as fast. This means the loop overhead accounts for
about half the work of the first definition of this function.

Update: It was pointed out in the comments that this particular example is
equivalent to a cond. That’s literally true all the way down to the byte-code,
and it would be a clearer way to express the unrolled code. In real code it’s
often not quite equivalent.

Unlike some of the other guidelines, this is certainly something you’d only
want to do in code you know for sure is performance-critical. Maintaining
unrolled code is tedious and error-prone.

I’ve had the most success with this approach by not by unrolling these loops
myself, but by [[http://nullprogram.com/blog/2016/12/27/][using a macro]], or [[http://nullprogram.com/blog/2016/12/11/][similar]], to generate the unrolled form.

#+BEGIN_SRC emacs-lisp
  (defmacro with-detect (var list)
    (cl-loop for e in list
             collect `(and (= 0 (% ,var ,e)) ,e) into conditions
             finally return `(or ,@conditions)))

  (defun detect-unrolled (x)
    (with-detect x (2 3 5 7 11 13 17 19 23 29 31)))
#+END_SRC

How can I find more optimization opportunities myself?

Use M-x disassemble to inspect the byte-code for your own hot spots. Observe
how the byte-code changes in response to changes in your functions. Take note
of the sorts of forms that allow the byte-code compiler to produce the best
code, and then exploit it where you can.
